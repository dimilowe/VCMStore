You are building a production-ready MVP web app called VCM AI Thumbnail Coach.
Goal:
A creator uploads a YouTube thumbnail image →
gets an instant AI analysis dashboard (scores + feedback), and
can continue with a chat-style AI consultant under the analysis for deeper help.
No auth, no accounts. Simple, fast, and safe.
1. Tech Stack
Use:
Backend: Node.js + Express
Frontend: Server-rendered HTML using EJS templates + vanilla JS (Fetch API)
Styling: Tailwind CSS compiled to a single CSS file
File upload: multer for handling image upload
AI: OpenAI official Node SDK (GPT-4.1 or GPT-4o with vision)
State: No DB. Chat history lives in the browser (JS), sent with each request.
Environment:
Add .env support with dotenv
Use process.env.OPENAI_API_KEY for the OpenAI key
2. Overall UX
Single-page flow at /:
Hero section
Title: “AI YouTube Thumbnail Coach (Free)”
Subtitle explaining what it does in 1–2 sentences.
Simple upload form for the thumbnail image.
Analyzer Section (appears after upload)
Shows the uploaded thumbnail preview.
Shows scores (0–100) for:
Clarity
Intrigue
Emotion
Contrast
Text Readability
Composition
A short overall verdict (1–2 sentences).
A bulleted list of “What’s Working” and “What to Improve”.
3–5 concrete suggestions.
Chat Section (always visible under analyzer once analysis is done)
Title: “Chat with Your AI Thumbnail Coach”.
Short intro text.
Chat UI:
Message history area (user + AI bubbles).
Text input box.
Optional “Attach another thumbnail” upload in chat.
Uses the last analysis as context, plus full chat history.
Everything must be mobile-friendly.
3. Routes & Controllers
3.1 GET /
Renders the main page.
Shows:
Intro hero section.
Upload form.
If query param session or some flag is present, can show prior analysis data; but for MVP, initial load = no analysis, no chat history.
3.2 POST /analyze
Accepts multipart/form-data with field: thumbnail (image file).
Validations:
Only allow PNG/JPEG.
Max size ~ 5MB.
Steps:
Use multer to store the file temporarily (/tmp in Replit is fine).
Read the file into a buffer.
Call OpenAI Vision with a carefully constructed system prompt (see section 4) asking for JSON output containing:
scores (clarity, intrigue, emotion, contrast, readability, composition 0–100)
overallVerdict (string)
whatsWorking (string[])
whatToImprove (string[])
suggestions (string[])
Parse the JSON safely (include try/catch; if parsing fails, show a generic error).
Delete the temp file after reading.
Response:
If request is from the main HTML form (normal POST), redirect or render the same EJS template with:
analysis object (parsed JSON)
thumbnailDataUrl or static path for the uploaded image preview
Alternatively, you can make this endpoint return JSON and call it via JS fetch; choose the simpler pattern but keep it clean.
Preferred approach:
Use JS fetch to POST /analyze and return JSON:
Request: FormData with file.
Response JSON shape:
{
  "success": true,
  "imageUrl": "/uploads/xyz.jpg" or "data:image/...",
  "analysis": {
    "scores": {
      "clarity": 78,
      "intrigue": 65,
      "emotion": 72,
      "contrast": 83,
      "readability": 70,
      "composition": 80
    },
    "overallVerdict": "Strong composition but text readability can be improved.",
    "whatsWorking": ["Subject is clear", "Good use of contrast"],
    "whatToImprove": ["Text is too small on mobile", "Background is busy"],
    "suggestions": [
      "Increase text size by ~20%",
      "Add subtle dark overlay behind text",
      "Crop closer to the subject’s face"
    ]
  }
}
The frontend JS updates the Analyzer section dynamically.
3.3 POST /chat
Accepts JSON:
{
  "messages": [
    { "role": "user" | "assistant" | "system", "content": "..." }
  ],
  "analysis": { ...same structure as above... },
  "thumbnailUrl": "optional string"
}
No server-side session storage; the client sends the full chat history and last analysis each time.
Server constructs a call to a chat completion model with:
A system prompt defining the role: “You are an AI YouTube Thumbnail Coach…”
A first assistant or system message summarizing the analysis object if provided.
Then the user+assistant messages from the request.
Response JSON:
{
  "success": true,
  "reply": "AI response text here"
}
The frontend appends this to the chat UI.
4. OpenAI Usage
Use the official OpenAI Node SDK.
4.1 Vision Call for /analyze
Use GPT-4.1 or GPT-4o with image support.
System message should instruct:
You are an expert YouTube thumbnail performance analyst. The user will send you one thumbnail image. Return JSON ONLY, no extra text. The JSON must have:
scores: { clarity, intrigue, emotion, contrast, readability, composition } (all 0–100)
overallVerdict: short human-readable summary (string)
whatsWorking: array of bullet points, what is strong
whatToImprove: array of bullet points, weaknesses
suggestions: array of concrete improvement ideas
Assume the thumbnail will be viewed mostly on mobile YouTube. Focus on CTR potential.
User payload includes the image (buffer) and a single text message: “Analyze this thumbnail.”
Parse the JSON from message.content.
4.2 Chat Call for /chat
System prompt example:
You are VCM AI Thumbnail Coach, a brutally honest but constructive YouTube thumbnail consultant. You help creators improve CTR by critiquing their thumbnails, titles, and hooks. Be specific, concrete, and actionable. Reference the previous analysis when relevant. Keep answers concise but detailed enough to be useful.
First assistant message (optional): include a compact summary of analysis (scores + key points).
Then append the messages from the client.
Return the assistant’s reply text.
Keep token usage reasonable (no long essays).
5. Frontend Implementation
Use EJS for layout, but most interactivity is done via vanilla JS.
5.1 Layout
Top nav: simple brand “VCM Suite — AI Thumbnail Coach”
Hero: H1, short description, upload form.
Main sections (stacked on mobile, two-column on desktop if you want):
Left / Top: Upload + Analyzer
Right / Bottom: Chat
5.2 Analyzer UI
After a successful /analyze call, display:
Thumbnail preview image.
Scores in a grid (use Tailwind progress bars or numeric badges).
Two columns:
“What’s Working”
“What to Improve”
A “Suggested Changes” list.
Optional: tag like “Overall Grade: B+” derived from average score.
This section should be visually impressive but clean.
5.3 Chat UI
Simple chat window:
Scrollable div for messages.
Messages styled differently for user vs AI.
Input row:
Textarea or input.
“Send” button.
Optional secondary file input to upload another thumbnail inside the chat; when there’s a new thumbnail, you can repeat the /analyze call and append analysis summary into the chat.
Chat logic:
Maintain an array chatMessages in JS like:
let chatMessages = [
  { role: "system", content: "You are VCM Thumbnail Coach..." }
];
On user send:
Push { role: "user", content: userInput } into chatMessages.
POST /chat with chatMessages (excluding initial system message, you can recreate that on server) and current analysis.
Append AI reply to chatMessages and UI.
6. Tailwind & Styling
Configure Tailwind and build one static CSS file in public/css/styles.css.
Style goals:
Centered layout with max width ~960px.
Card-style sections with rounded corners and soft shadow.
Neutral background, high contrast for text.
Progress bars or circular score badges for each metric.
Chat bubbles with light/dark differences.
7. Error Handling & Safeguards
If OpenAI call fails:
Show a user-friendly message: “Something went wrong analyzing your thumbnail. Please try again.”
Validate file type & size on both client and server.
Don’t store uploaded files permanently; keep them in /tmp or delete after getting a Data URL. For MVP you can:
Read the file into memory
Convert to a data URL (data:image/...) and send that back for preview
Delete the temp file.
8. Files & Structure
Suggested structure:
index.js (Express app)
/views
layout.ejs
index.ejs
/public
/css/styles.css
/js/app.js (front-end logic for analyze + chat)
/routes (optional) or keep routes in index.js
tailwind.config.js
package.json
.env (not committed)
9. README
Add a README explaining:
What the app does.
How to run locally on Replit:
npm install
npx prisma generate if you add Prisma later (not needed for this MVP now)
npm start
How to set OPENAI_API_KEY.
Core priorities:
Upload thumbnail → fast, reliable OpenAI vision analysis → clean UI.
Chat under the analysis, using that analysis as context.
No auth, no DB, minimal complexity.
Code should be clean and easy to extend later (for A/B, saving analyses, et